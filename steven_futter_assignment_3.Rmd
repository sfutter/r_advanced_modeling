---
title: 'Assignment #3: Predictive Modeling in Binary Classification'
author: "Steven Futter"
date: "2/7/2017"
output: html_document
---


In this assignment I develop a predictive modeling framework for a classification model. Before I perform any statistical analysis I perform a data quality check and an exploratory data analysis.

| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)
|
| 48 continuous real [0,100] attributes of type word_freq_WORD 
| = percentage of words in the e-mail that match WORD,
| i.e. 100 * (number of times the WORD appears in the e-mail) / 
| total number of words in e-mail.  A "word" in this case is any 
| string of alphanumeric characters bounded by non-alphanumeric 
| characters or end-of-string.
|
| 6 continuous real [0,100] attributes of type char_freq_CHAR
| = percentage of characters in the e-mail that match CHAR,
| i.e. 100 * (number of CHAR occurences) / total characters in e-mail
|
| 1 continuous real [1,...] attribute of type capital_run_length_average
| = average length of uninterrupted sequences of capital letters
|
| 1 continuous integer [1,...] attribute of type capital_run_length_longest
| = length of longest uninterrupted sequence of capital letters
|
| 1 continuous integer [1,...] attribute of type capital_run_length_total
| = sum of length of uninterrupted sequences of capital letters
| = total number of capital letters in the e-mail
|
| 1 nominal {0,1} class attribute of type spam
| = denotes whether the e-mail was considered spam (1) or not (0), 
| i.e. unsolicited commercial e-mail.  
|
| For more information, see file 'spambase.DOCUMENTATION' at the
| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html


```{r}
# set up necessary libraries
library(plyr)
library(dplyr)

### Read Data from csv file
inPath = file.path("~/Dropbox","NU","ADVANCED_MODELING","spambase")
spam = read.csv(file.path(inPath,"spambase.data"),na.strings=c("NA"," "),header=F)
column.names = c('word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over','word_freq_remove',
'word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will','word_freq_people',
'word_freq_report','word_freq_addresses','word_freq_free','word_freq_business','word_freq_email','word_freq_you',
'word_freq_credit','word_freq_your','word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl',
'word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data',
'word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',
'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(','char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest','capital_run_length_total','SPAM')
colnames(spam) = column.names
attach(spam)
```


##### (1) Data Quality Check:

```{r}
head(spam)
str(spam)
names(spam)
dim(spam)
summary(spam)
```


```{r echo=F}
maxfun            <- function(x){round(max(x,na.rm = TRUE),2)} 
minfun            <- function(x){round(min(x,na.rm = TRUE),2)}   
quantilefun       <- function(x){round(quantile(x,c(0.01,0.05,0.25,0.5,0.75,0.95,0.99)),2)}
meanfun           <- function(x){round(mean(x),2)}
varfun            <- function(x){round(var(x),2)}
percentMissingfun <- function(x){round(100*(sum(is.na(x))/length(x)),2)}

my.summary = function(df){
  max = colwise(maxfun)(df)                        #create rows of summarized values using colwise function from plyr package
  min = colwise(minfun)(df)
  quantile = colwise(quantilefun)(df)
  mean = colwise(meanfun)(df)
  variance = colwise(varfun)(df)
  percentMissing = colwise(percentMissingfun)(df)
  
  # bind data.frame and rename rows
  mydf = rbind(min, quantile, max, mean, variance, percentMissing)
  rownames(mydf) = c('min',0.01,0.05,0.25,0.5,0.75,0.95,0.99,'max','mean','variance','% missing')
  return(t(mydf)) # take transpose
}
```

Let's start by creating a frequency table for spam and non-spam emails. 
```{r}
# split out spam data set into spam and non-spam data.frames
yes.spam = subset(spam, SPAM=='1')
no.spam  = subset(spam, SPAM=='0')

# create data frame of spam and non-spam
spam.summary = my.summary(spam)
spam.summary = data.frame(spam.summary)

yes.spam.summary = my.summary(yes.spam)
yes.spam.summary = data.frame(yes.spam.summary)

no.spam.summary = my.summary(no.spam)
no.spam.summary = data.frame(no.spam.summary)

df1 = cbind(no.spam.summary$min,      yes.spam.summary$min,
            no.spam.summary$X0.05,    yes.spam.summary$X0.05,
            no.spam.summary$X0.5,     yes.spam.summary$X0.5,
            no.spam.summary$X0.95,    yes.spam.summary$X0.95,
            no.spam.summary$max,      yes.spam.summary$max,
            no.spam.summary$mean,     yes.spam.summary$mean,
            no.spam.summary$variance, yes.spam.summary$variance,
            no.spam.summary$X..missing, yes.spam.summary$X..missing)

df1 = data.frame(df1)

colnames(df1) = c('No 0.05','Yes 0.05',
                  'No 0.5','Yes 0.5',
                  'No 0.95','Yes 0.95',
                  'No Min','Yes Min',
                  'No Max','Yes Max',
                  'No Mean','Yes Mean',
                  'No Variance','Yes Variance',
                  'No % Missing','Yes % Missing')

rownames(df1) = column.names
df1
```


##### Missing Data
The my.summary() function above confirms that there are no missing observations in either the spam or non-spam email observations. 

##### Data Ranges and Distributions
The my.summary() function output also provides insight into the distribution of various different word and character frequencies, as well as the capital letter run length average, run length longest, and run length total. There are 4601 observations and 58 variables in the spam dataset of which 61% (2788 out of 4601) are non-spam emails and 39% (1813 out of 4601) are spam. 

#### Differences across spam and non-spam observations
The 'Capital Run Length Average' measures the average length of uninterrupted sequences of capital letters. Spam emails often need to attract the readers attention so this may not come as a surprise. The mean for this variable differs from 2.38 for non-spam to 9.52 for spam emails. The non-spam minimum average length of uninterupted sequences of capital letters is 4.68	in comparison to the spam minimum average length of uninterupted sequences of capital which is 15.68. Again, for the maximum number of non-spam and spam uninterrupted sequences of capital letters with 251.00 and 1102.50 letters respectively. It is evident that the spam and no-spam observations differ considerably by their use of capital letters. These variables look to be promising predictors, but let's investigate further. 

##### Outliers
By using a boxplot approach I identify several extreme outliers for the variables word_freq_3d, capital_run_length_total, and capital_run_length_longest. An outlier is defined as a data point that is located outside the fences, or whiskers, of the boxplot (e.g: outside 1.5 times the interquartile range above the upper quartile and bellow the lower quartile). However, for the purpose of the initial quality check I refer to only the extreme values that stand out amongst the observations. For word_freq_3d the extreme values can be seen with values greater than 30, and for capital_run_length_total and capital_run_length_longest for values greater than 5,000. 

```{r}
# Example of outliers for the word_freq_3d variable. Example outliers with values > 30.  
op <- par(mar = c(5, 10, 4, 2) + 0.1)
boxplot(spam[,c('word_freq_3d')], data = spam, horizontal = TRUE, las = 1, cex.axis = 0.7)
## reset the plotting parameters
par(op)

# Example of outliers for the capital_run_length_total and capital_run_length_longest variables. Example outliers with values > 5,000.
op <- par(mar = c(5, 10, 4, 2) + 0.1) # Update 
boxplot(spam[,56:57], data = spam, horizontal = TRUE, las = 1, cex.axis = 0.7)
## reset the plotting parameters
par(op)

```


##### (2) Exploratory Data Analysis:
With the spam data set we have a binary classification problem: either an observation is spam, or it is not. After removing the extreme outliers with values in excess of 5,000 we can see that capital_run_length_total is higher for the middle 75% (grey shaded bar) of values for spam emails. Although there is some overlap the whiskers of the boxplot for spam=1 extend far higher. The same finding can be made by looking at the capital_run_length_taotal variable in that the middle 75% (grey shaded bar) of values for spam emails is higher and the upper whisker extends far higher for spam in comparison to non-spam emails. I exclude values here that are in excess of 500 to make this distinction clearer. This finding highlights that spam emails contains a proportionately larger percentage of capital letters in comparison to non-spam emails. To get the readers attention spammers will use capital letters.  

```{r}
temp = spam %>% filter(capital_run_length_total<5000)
boxplot(capital_run_length_total~SPAM,   data=temp, col='lightgray',xlab="capital_run_length_total", ylab='spam',horizontal=TRUE)

temp = spam %>% filter(capital_run_length_total<500)
boxplot(capital_run_length_longest~SPAM, data=temp, col='lightgray',xlab="capital_run_length_total", ylab='spam',horizontal=TRUE)
```


Emails received with higher frequencies of the words 'free' and 'money' tend to be spam.   
```{r}
xyplot(word_freq_money ~ word_freq_free  | factor(SPAM), data = spam, type = "h", layout = c(1, 2), xlab = "word_freq_free")
```


I now use a tree model to explore the data further and evaluate missclassification error. 
head(spam)
##### Tree Model 
```{r}
require(rpart)
require(rattle)
require(rpart.plot)
# diamonds = diamonds[,-8]  
#dropIdx1 = which(names(spam) %in% c("priceCut")) # remove priceCut variable as this will throw off the results
#diamonds = diamonds[,-dropIdx1]

# Plot a more reasonable tree
form <- as.formula(SPAM ~ .)
tree <- rpart(form,spam)            # A more reasonable tree
fancyRpartPlot(tree)                # A fancy plot from rattle

```

At the root of the tree the 0.39 denotes that 39% of the 4601 observations are spam emails. The root is split at char_freq_$<0.056 and this highlights that the frequency with which the $ sign appears in the email is the most predictive factor input. Of the 4601 observations 25% have a char_freq_$ greater than 0.056. Of these 88% are spam emails. Other variables that appear in the top five most important predictive variables from looking at  summary(tree) of the tree are: char_freq_$, word_freq_remove, word_freq_money,word_freq_000, and char_freq_!.





##### (3) The Model Build
Letâ€™s begin the model building process by splitting the spam data set into a training and test data set. 

```{r}
smp.size = floor(0.7 * nrow(spam))
set.seed(1)
train = sample(seq_len(nrow(spam)), size = smp.size)
test = -train
spam.train = spam[train,]
spam.test  = spam[-train,]
```


##### 1. Logistic Regression Model using Variable Selection
```{r}
### MODEL 1 creation using divido1 culled data set
fullmod = glm(SPAM ~ .,data=spam.train, family=binomial)
summary(fullmod)

nothing <- glm(SPAM ~ 1,data=spam.train, family=binomial)
summary(nothing)
 
# forward variable selection
forwards = step(nothing,scope=list(lower=formula(nothing),upper=formula(fullmod)), direction="forward")
formula(forwards)
```

Final Model Selected by a forward variable selection algorithm has an AIC of 1346.28. 
Step:  AIC=1346.28
SPAM ~ `char_freq_$` + word_freq_hp + capital_run_length_longest + 
    word_freq_george + word_freq_free + word_freq_edu + word_freq_remove + 
    word_freq_business + word_freq_meeting + word_freq_000 + 
    word_freq_money + word_freq_cs + word_freq_internet + word_freq_re + 
    `char_freq_!` + word_freq_your + word_freq_conference + word_freq_credit + 
    word_freq_our + word_freq_project + word_freq_order + word_freq_original + 
    word_freq_technology + word_freq_over + word_freq_650 + word_freq_pm + 
    word_freq_you + word_freq_lab + word_freq_85 + word_freq_3d + 
    word_freq_address + word_freq_data + word_freq_will + capital_run_length_total + 
    `char_freq_;` + `char_freq_#` + word_freq_addresses + word_freq_hpl + 
    word_freq_make + word_freq_table + word_freq_direct
    
    
```{r}
#backwards is the default selection method 
backwards = step(fullmod) # Backwards selection is the default 
# backwards = step(fullmod,trace=0) would suppress step by step output.
formula(backwards)
```

Step:  AIC=1346.28
SPAM ~ word_freq_make + word_freq_address + word_freq_3d + word_freq_our + 
    word_freq_over + word_freq_remove + word_freq_internet + 
    word_freq_order + word_freq_will + word_freq_addresses + 
    word_freq_free + word_freq_business + word_freq_you + word_freq_credit + 
    word_freq_your + word_freq_000 + word_freq_money + word_freq_hp + 
    word_freq_hpl + word_freq_george + word_freq_650 + word_freq_lab + 
    word_freq_data + word_freq_85 + word_freq_technology + word_freq_pm + 
    word_freq_direct + word_freq_cs + word_freq_meeting + word_freq_original + 
    word_freq_project + word_freq_re + word_freq_edu + word_freq_table + 
    word_freq_conference + `char_freq_;` + `char_freq_!` + `char_freq_$` + 
    `char_freq_#` + capital_run_length_longest + capital_run_length_total
    
The same as forward variable selection on AIC. 


```{r}    
bothways = step(nothing, list(lower=formula(nothing),upper=formula(fullmod)),direction="both")
formula(bothways)
```

Final Model Selected by the stepwise variable selection algorithm has an AIC of 1346.28. 
Step:  AIC=1346.28
SPAM ~ `char_freq_$` + word_freq_hp + capital_run_length_longest + 
    word_freq_george + word_freq_free + word_freq_edu + word_freq_remove + 
    word_freq_business + word_freq_meeting + word_freq_000 + 
    word_freq_money + word_freq_cs + word_freq_internet + word_freq_re + 
    `char_freq_!` + word_freq_your + word_freq_conference + word_freq_credit + 
    word_freq_our + word_freq_project + word_freq_order + word_freq_original + 
    word_freq_technology + word_freq_over + word_freq_650 + word_freq_pm + 
    word_freq_you + word_freq_lab + word_freq_85 + word_freq_3d + 
    word_freq_address + word_freq_data + word_freq_will + capital_run_length_total + 
    `char_freq_;` + `char_freq_#` + word_freq_addresses + word_freq_hpl + 
    word_freq_make + word_freq_table + word_freq_direct
    


##### 2. Tree Model
Note that there are several variables with characters in them that I need to rename since they can not be accepted in the tree model. I'll rename these variables first before running the model. 
```{r}
#spam.train = spam.train[,-59]
spam.train$char_freq_semi_colon_symbol  = spam.train[,49] #char_freq_;
spam.train$char_freq_exclamation_symbol = spam.train[,52] #char_freq_!
spam.train$char_freq_dollar_symbol      = spam.train[,53] #char_freq_$
spam.train$char_freq_number_symbol      = spam.train[,54] #char_freq_#

names(spam.train)

#dropIdx1 = which(names(spam) %in% c("char_freq_;")) # remove priceCut variable as this will throw off the results
#spam.train = spam.train[,-dropIdx1]

```


```{r}
library(tree)
set.seed(1)
tree.fit=tree(SPAM~
    word_freq_make + word_freq_address + word_freq_3d + word_freq_our +
    word_freq_over + word_freq_remove + word_freq_internet + 
    word_freq_order + word_freq_will + word_freq_addresses + 
    word_freq_free + word_freq_business + word_freq_you + word_freq_credit + 
    word_freq_your + word_freq_000 + word_freq_money + word_freq_hp + 
    word_freq_hpl + word_freq_george + word_freq_650 + word_freq_lab + 
    word_freq_data + word_freq_85 + word_freq_technology + word_freq_pm + 
    word_freq_direct + word_freq_cs + word_freq_meeting + word_freq_original + 
    word_freq_project + word_freq_re + word_freq_edu + word_freq_table + 
    word_freq_conference + char_freq_semi_colon_symbol + char_freq_exclamation_symbol + char_freq_dollar_symbol + 
    char_freq_number_symbol + capital_run_length_longest + capital_run_length_total
    
    ,data=spam.train)
summary(tree.fit)
```

The tree is constructed with a reduced subset of nine , including 10 terminal nodes.  In the context of a regression tree, the deviance (Residual mean deviance = 0.07236) is simply the sum of squared error for the tree. The variables included in the tree are: "char_freq_dollar_symbol", "word_freq_remove", "char_freq_exclamation_symbol", "word_freq_free", "word_freq_money", "capital_run_length_total", "word_freq_george", "word_freq_hp", and "word_freq_edu".

##### 3. Support Vector Machine Model

##### 4. Random Forest Model
```{r}
library(randomForest)
set.seed(1)
randomForest.fit = randomForest(SPAM~capital_run_length_average + word_freq_parts + word_freq_conference, data=d.train, mtry=3, importance=TRUE)
randomForest.fit
```




##### (4) Model Comparison
Construct tables to compare model performance both in-sample and out-of-sample, and discuss
your results. Which model performed best?
Presentation:
The presentation of your results is open to you. Remember that the objective of your analysis is to
effectively communicate the important information. At a minimum your presentation should include a
section for the data quality check (where you discuss the overall approach that you used and any
interesting results), a section for the exploratory data analysis (where you present and discuss your
interesting findings, and an appendix of relevant R code related to the results or graphics that you have
presented.

Assignment Document:
Students should present their results in the form of a report. Reports should be well written. Results
should be embedded into the report in the sections with the corresponding discussion. All figures and
tables should be centered and labelled. Samples of relevant R code related to the output discussed in
the report should be included in an appendix. This should not be all of your R code, only some of the
relevant R code. For example if you made a very specific statistical graphic that you discuss in the
report, then the R code for that statistical graphic should be included in your appendix. The R code used
to fit any statistical models should always be included in the appendix.
The report document should be submitted in pdf format.


DPLYR if I need it
```{r}
hourly_delay = flights %>%         # treat %>% as a 'then' statement... E.g. get flights, then, filter on dep_delay..
  filter(!is.na(dep_delay)) %>%
  group_by(year, month) %>%
  summarise(
    delay = mean(dep_delay),
    n=n()                         # gets the number of flights in each group.
  ) %>%
  filter(n>10)  
hourly_delay
```


